The following two sections describes the two CUDA implementations made during this project. The first implementation, MiddlePar, was the first iteration on how we could parallelise the mathematical model described earlier. The second implementation, OuterPar, is an improved version of the first that further parallelise. Both CUDA implementations derive directly from the C implementation described earlier.

\subsection{MiddlePar} \hfill \\
In order to parallelise the C implementation and make use of the parallelism of the GPU, we had to analyse the each model of the implementation. Our approach was to locate the most obvious part that could be parallelised, and developed a CUDA off that. Since the solution could not be parallelised entirely, we acknowledged that some calculations would be done on the GPU, the parts that could be parallelised, and the rest would be run on the CPU. The most obvious possibility for a CUDA solution is found within the middle model. Compared to both the outer and the inner model, the steps within the middle model were not very dependent on the previous steps. We say very because they are not completely independent. Middle is calculated by adding the result of k1, k2, k3, k4 and then add it with the y value of the previous step. This means that for each step we can calculate the sum of all the k values before we add it all together. This is a good start since the calculation of either k, is essentially a call to the inner model. This solution would keep the amount of inner model calls per thread to be only 4. The CUDA implementation of this is explained in section :MiddlePar:.

\subsubsection{Implementation} \hfill \\
The implementation of this CUDA solution is apparent in the function OuterDiff, which is the function that needs a result from the middle model. OuterDiff prepares two variables that is to be copied to the GPU. The first is the current x value from outer, that is needed to calculate middle, and an array called kSum. kSum is an array that will be used to store the sum of k1, k2, k3 and k4, calculated by each thread. Having these results, calculating each step in middle can be done much faster, since it is just a matter of adding two double values together for each step. \\
Based on the step size it is possible to calculate exactly how many steps middle needs to take. Prior to starting the kernel, we need to make sure that there are enough threads available when parallelising middle, such that there are at least one thread for each step. The amount of threads per block would be set prior to program execution, and before starting the kernel the amount of blocks needed to ensure enough threads would be automatically calculated.\\

In the following we will explain the kernel implementation; see figure (CODEFIGURE INSERT REFERENCE) for the changes made to middle. \\

Once the kernel has been started, each thread define their global thread id by calculating threadIdx.x + blockIdx.x*blockDim.x. This ensures that each thread within the kernel has a unique id, which we will need later on.\\

We then ensure that only threads, that has an id within the range of middle steps, continue on from line XX. We know that this will cause branch diversion in the last block if the total amount of threads is not equal to the amount of steps, however this is a necessary precaution as we will see soon.\\

The next couple of lines is used to calculate local variables, that is used to call both Inner(…) and MiddleDiff(…). k1, k2 and k4 is then calculated by calling MiddleDiff(…) and Inner(…). In line YY the weighted average of each k is calculated and stored in the kSum array. This is where it is important that the thread id does not exceed the amount of steps. The size of kSum is exactly the total amount of steps, so if a thread id is larger than this, we would run into problems. A solution could be to always make sure that the number of threads you have is equal to the amount of steps to be taken, however since both thread per block and, as well as middle steps varies it is not feasible, and cannot always be ensured. Once the sum of the k values have been stored in kSum for all threads, the kernel terminates.\\

\subsubsection{Memory considerations} \hfill \\
This CUDA implementation access certain constant variables quite a lot when calculating inner(…). Since we were ever only going to read these constants, it would be a good idea to place this information in constant memory. Constant memory is considerably faster than global memory(INSERT REFERENCE), with the limitation.\\

It was also considered to keep kSum in shared memory. Shared memory, like constant memory, is likewise considerably faster than global memory, however it is possible for more than one block to be part of the kernel execution. Shared memory allow tread within the same block to share data, but not between blocks, so shared memory was discarded for this solution, and kSum was kept in global memory.\\

\subsubsection{NVIDIA Analyser} \hfill \\
TODO

\subsubsection{Implementation shortages} \hfill \\
The solution described above have a few drawbacks. First of all, each time a call to middle are made, a new GPU context would be set up, variables would be copied to the GPU, and a new kernel would be started. Doing this for a low x value, and a high step size, would result create a large amount of kernels. Second, this solution need more than one block to parallelise middle if the amount of threads per block were low. Even though it would speed up the call to middle, it does not speed it up the amount of total calls made to middle. Third, we are not using a lot of threads or blocks to actually make the calculations, compared to how many threads and blocks are available on modern GPU’s. Fourth, it would be much more efficient to use shared memory for storing the kSum array, instead of keeping it in global memory.\\

We could of course address some of these issues, but since we are going to improve this implementation in the next section, it was decided not to further alter this implementation. \\
\subsection{OuterPar} \hfill \\
To address the shortages the GPU parallelisation of middle, we would have have to make some major changes to the existing GPU and CPU code. First we need to make sure that middle is ever only being calculated using the threads from within a single block. We also needed to change kSum to be a shared variable array instead of an input array. \\

Furthermore we had to parallelise the total calls to middle. Investigation showed that the differential equation of the outer integral, used only the current x value from the outer steps to calculate middle. This effectively meant that we could calculate all x values in advance (we knew the start x value, the end x value as well as the size of each step), and further calculate all calls to middle in advance using these values. These could all be calculated at once on the GPU using only one kernel. Together with the changes to middle this would allow us to run several blocks to calculate different middle calls at the same time and make better use of the GPU resources. The CUDA implementation is described in the following section.

\subsubsection{Implementation} \hfill \\

The first changes were made in Middle(…). The changes were made to address two of the issues described in (SECTION MiddlePar:::Implementation shortages:::), regarding the use of multiple blocks within a single call Middle(…), as well as the lack of a shared variable to store kSum. Figure XX shows the updated code. The first two changes is easily  visible. Since all threads that will calculate each step in Middle(…) is now always within the same block, we can define a shared variable (for much faster data storing) kSum, and we can define the thread id to be simply the id within the block(line xx).\\

The next change is that we can get the x value from outer, from a pre-calculated array, outerx, passed to the kernel at execution time. The x value needed for a specific block can then be accessed by indexing on the unique block id(line xx).\\

We further changed the if statement to a while loop and added a counter. Since the number of threads per block can be less than the number of steps to be taken, we want to ensure that threads iterate over multiple steps instead of just one, such that kSum will be correctly filled. It also ensures that if a block contains more threads than there are steps to be taken, they do not enter the while loop. Apart from the counter, everything within the while loop is the same as it was in figure (MIDDLEPAR CODE).\\

The next part of the code was done in OuterDiff(…) for the MiddlePar solution. This was because, when working with multiple blocks, one could never guarantee that all blocks had reached the same part of the code before moving on. The only situation where you know for certain that all blocks have finished execution is when the kernel terminates. For the MiddlePar solution we copied kSum back to the CPU and made it compute the sum there. However, now that we are only working within a single block we can make use of the \_\_syncthreads() statement. This statement ensures that all threads(within the same block) have gotten to this line of code before continueing. We also reset the thread id in case we had to loop. \\

Once we have calculated kSum for each thread we need to add it together to a single value. There are basically two ways to do this; using a single thread to iterate over all the values in kSum and add them together, or using reduction(insert CUDA by example reference). Reduction is a method where you make use of the threads already available, and have them add two values together, until you only have one value left. See figure XX for a visualization of this concept. This allow the sum of kSum to be computed in log2(threadsperblock) iterations.\\

Reduction seems like the most obvious choice, however there is a downside. For reduction to work you need an array, and a number of threads that are a power of 2 (insert CUDA by example reference). We can make sure that the number of threads per block is always a power of 2, however we can never guarantee that the same goes for the size of kSum. The size of kSum is 119 times the stepsize, and for good reasons this can never be guaranteed to be the power of 2. A solution to this would be to always make sure that the size of kSum is the power of 2, and then just fill the unused elements with zeros. However this overhead meant that we might as well just loop through kSum and sum everything together with a single thread. We therefore decided not to use reduction in this case.\\

Once the sum have been calculated it is stored in the input array temp using the block id for indexing. Once all blocks have executed, the kernel terminates and temp is copied back to the CPU. When OuterRK(…) is called from this point on, instead of calling Middle(…) whenever it solves the integral, it just indexes into temp.\\

\subsubsection{Memory considerations} \hfill \\

\subsubsection{NVIDIA Analyser} \hfill \\