%!TEX root = /Users/Nikolaj/Developer/GPU-Project/Report/Report.tex
This report is written at the IT University of Copenhagen (ITU) in the spring term of 2013 as a CUDA project supervised by Peter Sestoft from ITU and Hans Henrik Brandenborg SÃ¸rensen from the Technical University of Denmark (DTU). The report is addressed to people interested in exploiting the benefits of using general purpose graphical processing units (GPGPUs) to optimize feasible computations in general, but specifically to people interested in CUDA. \\

Graphical Processing Units (GPUs) are most commonly used to render graphics in computer games. GPGPUs are ``general purpose'' variants that share the same architecture as GPUs but are optimized for computing purposes out of line with the graphics category. Since this project is not about graphics, we will refer to GPGPUs simply as GPUs, for shortness, throughout the rest of the report.

In this project, we take a problem from the life insurance industry that requires a significant amount of time to solve and show how to speed it up using the GPU. The problem concerns life insurance policies for married people, where one of them receives an amount of money some time after the other person has died. The challenge faced by the insurance company is to estimate its current and future reserves as accurately as possible such that it is always able to satisfy the obligations to the insurance holders. Such an estimate is largely dependent on an estimate of when each insurance holder is going to die which can be anytime between signing of the policy and some, possibly large, number of years ahead in time. Furthermore, the time of death is dependent on several variables like age, gender etc. which has to be taken into account when making the estimate.\\

The insurance company has a mathematical model that unifies all these variables and calculates the reserves needed to insure a single insurance holder, should he die at any time between the time where the computation is done and some number of years ahead. The model describes the problem to an acceptable level of detail and can be solved by a computer but it takes a lot of time to do so, even with modern CPUs. Moreover, insurance companies typically issue several thousands of policies each of which needs to be solved separately. When solving the policies, tabulation can be used with an advantage which will be further discussed in Section \ref{reflection}. Thus, the time it takes to solve the model for a single policy has to be as small as possible in order not to increase the complexity of the overall computation, which, at the end of the day, is what the insurance company is interested in. \\

The goal of this project is to analyze the opportunity to speed up the computation for a single insurance holder through parallelism with CUDA based on a working sequential implementation in C\#. That is, we aim to optimize the time it takes to estimate the size of the reserve needed at any time during the life of an insurance holder such that the insurance company can fulfill its obligations when the person dies. To accomplish this goal, we implemented a version of the C\# solution in C to have a non-object oriented working implementation producing the same results as the C\# code and resembling the end product. From this implementation we were able to produce a fully parallelized implementation that achieves a substantial increase in speed compared to the original one.\\

The reader of the report is assumed to know the basic principles of concurrency and parallelism. No CUDA specific knowledge is required. The rest of the report is outlined as follows. Section \ref{background} provides some background information on the mathematical model from the insurance company and a general explanation of the principle behind the 4th order Runge-Kutta method used to solve it. Section \ref{problemdefinition}, \ref{scope} and \ref{assumptions} describes the problem definition, scope and project related assumptions. Section \ref{themath} describes the mathematical model and the 4th order Runge-Kutta method. Section \ref{implementation} explains the C implementation that we made as an intermediate step towards a fully parallel solution. Section \ref{cuda} gives a general introduction to the architecture behind CUDA and an explanation of CUDA specific terminology. Section \ref{realization} describes the parallelized solution which is evaluated and benchmarked in section \ref{testing} through \ref{bandc}. Section \ref{reflection} discusses the quality of the results. Section \ref{futurework} gives some suggestions for future work. Finally, Section \ref{conclusion} concludes the report.
