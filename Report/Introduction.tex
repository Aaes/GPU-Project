%!TEX root = /Users/Nikolaj/Developer/GPU-Project/Report/Report.tex
This report is written at the IT University of Copenhagen (ITU) in the spring term of 2013 in connection with a CUDA project supervised by Peter Sestoft from ITU and Hans Henrik Brandenborg SÃ¸rensen from the Technical University of Denmark (DTU). The report is addressed to people interested in exploiting the benefits of using general purpose graphical processing units (GPGPUs)\footnote{Graphical Processing Units (GPUs) are most commonly used to render graphics in computer games. GPGPUs are ``general purpose'' variants that share the same architecture as GPUs but are optimized for computing purposes out of line with the graphics category. Since this project is not about graphics, we will refer to GPGPUs simply as GPUs, for shortness, throughout the rest of the report.} to optimize feasible computations in general, but specifically to people interested in CUDA. \\

In this project, we take a problem from the life insurance industry that requires a significant amount of time to solve and show how to speed it up using the GPU. The problem concerns life insurance policies for married people, where one of them receives an amount of money some time after the other person has died. The challenge faced by the insurance company is to estimate its current and future holdings as accurately as possible such that it is always able to satisfy the obligations to the policyholders. Such an estimate is largely dependent on an estimate of when each policyholder is going to die which can be anytime between signing of the policy and some, possibly large, number of years ahead in time. Furthermore, the time of death is dependent on several variables like age, gender etc which has to be taken into account when making the estimate.\\

The insurance company has a mathematical model that unifies all these variables and calculates the reserves needed to insure a single policyholder, should she die at any time between the time where the computation is done and some number of years ahead. The model describes the problem to an acceptable level of detail and can be solved by a computer but it takes a lot of time to do so, even with modern CPUs. Moreover, insurance companies typically issue several thousands of policies each of which needs to be plugged in to the model and solved separately. Thus, the time it takes to solve the model for a single policy has to be as small as possible in order not to blow up the complexity of the overall computation, which, at the end of the day, is the one the insurance company is interested in. \\

All these facts together make computing power a valuable entity. The goal of this project is to analyze the opportunity to speed up the computation for a single policyholder through parallelism with CUDA based on a working sequential implementation in C\#. That is,  we aim to optimize the time it takes to compute the size of the reserves needed at any time during the life of a policyholder such that the insurance company can fulfill its obligations when the person dies. To accomplish this goal, we implemented a version of the C\# solution in traditional C to have a non-object oriented working implementation producing the same results as the C\# code and looking closer to the end product. From this implementation we were able to produce a fully parallelised implementation that achieves a substantial speed-up compared to the original one.\\

The reader of the report is assumed to know the basic principles of concurrency and parallelism. No CUDA specific knowledge is required. The rest of the report is outlined as follows. Section 2 provides some background information on the mathematical model from the insurance company and a general explanation of the principle behind the 4th order Runge Kutta method used to solve it. Section 3 explains the C implementation that we made as an intermediate step towards a fully parallel solution. Section 4 gives a general introduction to the architecture behind CUDA and an explanation of CUDA specific terminology. Section 5 describes the parallelised solution the mathematical model which is evaluated and benchmarked in section 6 through 7. Section 8 discusses the quality of the results. Section 9 gives some suggestions for future work. Finally, Section 10 concludes the report.
